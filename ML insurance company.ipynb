{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de prestaciones de seguro: Modelo de Machine Learning en Sure Tomorrow por *Carlos Horta* (carlosgim@gmail.com)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto: Soluciones de Machine Learning para Sure Tomorrow\n",
    "\n",
    "Sure Tomorrow, una compañía de seguros, busca aprovechar el poder del Machine Learning para resolver varias tareas y mejorar sus operaciones. A continuación, se describen las tareas planteadas y los objetivos correspondientes:\n",
    "\n",
    "## Tarea 1: Identificación de clientes similares\n",
    "El objetivo de esta tarea es encontrar clientes que sean similares a un cliente determinado. Esto ayudará a los agentes de la compañía en sus estrategias de marketing. Utilizando técnicas de Machine Learning, se desarrollará un modelo que pueda identificar características y patrones comunes entre los clientes para sugerir grupos de clientes similares. Esta información permitirá una segmentación más efectiva y personalizada, mejorando las estrategias de marketing de Sure Tomorrow.\n",
    "\n",
    "## Tarea 2: Predicción de probabilidad de prestación del seguro\n",
    "En esta tarea, el objetivo es predecir la probabilidad de que un nuevo cliente reciba una prestación del seguro. Se comparará el desempeño de un modelo predictivo con el de un modelo dummy para determinar si el enfoque predictivo puede lograr mejores resultados. Utilizando datos históricos, se desarrollará un modelo de Machine Learning capaz de estimar la probabilidad de que un cliente reciba una prestación, lo que brindará a Sure Tomorrow una herramienta valiosa para tomar decisiones basadas en riesgos y mejorar su gestión de reclamaciones.\n",
    "\n",
    "## Tarea 3: Predicción del número de prestaciones de seguro\n",
    "En esta tarea, el objetivo es predecir el número de prestaciones de seguro que un nuevo cliente pueda recibir. Se utilizará un modelo de regresión lineal para estimar el número de prestaciones en función de diversas características del cliente. El modelo de regresión lineal proporcionará a Sure Tomorrow una estimación cuantitativa del número de prestaciones que un cliente podría requerir, lo que facilitará la planificación y la gestión de recursos.\n",
    "\n",
    "## Tarea 4: Protección de datos personales mediante enmascaramiento\n",
    "En esta tarea, el objetivo es desarrollar un algoritmo de enmascaramiento u ofuscación de datos para proteger la información personal de los clientes sin afectar la calidad de los modelos de Machine Learning desarrollados en las tareas anteriores. El algoritmo garantizará que los datos personales estén protegidos de manera segura y que no puedan ser recuperados por personas no autorizadas. Esto permitirá a Sure Tomorrow cumplir con las regulaciones de privacidad de datos y garantizar la confidencialidad de la información de sus clientes.\n",
    "\n",
    "En general, el proyecto busca aprovechar las capacidades del Machine Learning para mejorar el marketing, la toma de decisiones basada en riesgos y la protección de datos en Sure Tomorrow. La implementación exitosa de estas tareas brindará a la compañía herramientas valiosas para optimizar sus operaciones y ofrecer un servicio más eficiente y seguro a sus clientes.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento y exploración de datos\n",
    "\n",
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (0.24.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.21.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 57.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.8.0)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'INSTALLER'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga los datos y haz una revisión básica para comprobar que no hay problemas obvios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('insurance_us.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/insurance_us.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombramos las columnas para que el código se vea más coherente con su estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4418</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age   income  family_members  insurance_benefits\n",
       "4242       1  39.0  28200.0               1                   0\n",
       "73         1  32.0  15600.0               2                   0\n",
       "885        1  20.0  42700.0               2                   0\n",
       "841        1  44.0  22700.0               3                   1\n",
       "4679       0  39.0  50000.0               3                   0\n",
       "4418       1  38.0  29800.0               3                   0\n",
       "4108       0  32.0  39400.0               0                   0\n",
       "2792       0  40.0  21100.0               0                   0\n",
       "2808       0  20.0  38200.0               1                   0\n",
       "4946       1  26.0  32600.0               2                   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   gender              5000 non-null   int64  \n",
      " 1   age                 5000 non-null   float64\n",
      " 2   income              5000 non-null   float64\n",
      " 3   family_members      5000 non-null   int64  \n",
      " 4   insurance_benefits  5000 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puede que queramos cambiar el tipo de edad (de float a int) aunque esto no es crucial\n",
    "\n",
    "# escribe tu conversión aquí si lo deseas:\n",
    "df['age'] = df['age'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   gender              5000 non-null   int64  \n",
      " 1   age                 5000 non-null   int64  \n",
      " 2   income              5000 non-null   float64\n",
      " 3   family_members      5000 non-null   int64  \n",
      " 4   insurance_benefits  5000 non-null   int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "# comprueba que la conversión se haya realizado con éxito\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  age   income  family_members  insurance_benefits\n",
      "0       1   41  49600.0               1                   0\n",
      "1       0   46  38000.0               1                   1\n",
      "2       0   29  21000.0               0                   0\n",
      "3       0   21  41700.0               2                   0\n",
      "4       1   28  26100.0               0                   0\n",
      "----------------\n",
      "            gender          age        income  family_members  \\\n",
      "count  5000.000000  5000.000000   5000.000000     5000.000000   \n",
      "mean      0.499000    30.952800  39916.360000        1.194200   \n",
      "std       0.500049     8.440807   9900.083569        1.091387   \n",
      "min       0.000000    18.000000   5300.000000        0.000000   \n",
      "25%       0.000000    24.000000  33300.000000        0.000000   \n",
      "50%       0.000000    30.000000  40200.000000        1.000000   \n",
      "75%       1.000000    37.000000  46600.000000        2.000000   \n",
      "max       1.000000    65.000000  79000.000000        6.000000   \n",
      "\n",
      "       insurance_benefits  \n",
      "count         5000.000000  \n",
      "mean             0.148000  \n",
      "std              0.463183  \n",
      "min              0.000000  \n",
      "25%              0.000000  \n",
      "50%              0.000000  \n",
      "75%              0.000000  \n",
      "max              5.000000  \n"
     ]
    }
   ],
   "source": [
    "# ahora echa un vistazo a las estadísticas descriptivas de los datos.# ¿Se ve todo bien?\n",
    "\n",
    "print(df.head())\n",
    "print('----------------')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  age  income  family_members  insurance_benefits\n",
      "0       1   41   49600               1                   0\n",
      "1       0   46   38000               1                   1\n",
      "2       0   29   21000               0                   0\n",
      "3       0   21   41700               2                   0\n",
      "4       1   28   26100               0                   0\n"
     ]
    }
   ],
   "source": [
    "# la columna 'income' puede ser un poco difícil de leer, así que vamos a dejarla con únicamente números enteros\n",
    "\n",
    "df['income'] = df['income'].astype('int')\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar rápidamente si existen determinados grupos de clientes observando el gráfico de pares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.pairplot(df, kind='hist')\n",
    "g.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Es cierto, detectar grupos o clústeres en conjuntos de datos con múltiples variables simultáneamente puede ser un desafío. Sin embargo, es precisamente en estos casos donde el análisis y el Machine Learning pueden ser herramientas muy útiles.\n",
    "\n",
    "El análisis de datos multivariados permite examinar las relaciones entre múltiples variables al mismo tiempo, lo que facilita la detección de patrones y la identificación de clústeres. Mediante técnicas de visualización y análisis estadístico, es posible explorar las distribuciones multivariadas y comprender las relaciones complejas entre las variables.\n",
    "\n",
    "El Machine Learning también puede desempeñar un papel importante en la detección de clústeres. Los algoritmos de agrupamiento, como el k-means, el clustering jerárquico o el DBSCAN, pueden analizar patrones en los datos y agrupar puntos similares en clústeres. Estos algoritmos pueden manejar múltiples variables y encontrar estructuras ocultas en los datos, lo que puede ayudar a identificar grupos de manera automatizada.\n",
    "\n",
    "Además, técnicas más avanzadas de Machine Learning, como el aprendizaje no supervisado o el aprendizaje profundo, también pueden ser utilizadas para descubrir relaciones y patrones complejos en conjuntos de datos multivariados.\n",
    "\n",
    "En resumen, tanto el análisis de datos multivariados como el Machine Learning pueden ser herramientas valiosas en la detección de clústeres en conjuntos de datos con múltiples variables. Estas técnicas permiten explorar las distribuciones multivariadas y descubrir patrones y relaciones ocultas, lo que puede ser de gran ayuda en la comprensión y el análisis de conjuntos de datos complejos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1. Clientes similares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el lenguaje de ML, es necesario desarrollar un procedimiento que devuelva los k vecinos más cercanos (objetos) para un objeto dado basándose en la distancia entre los objetos.\n",
    "Es posible que quieras revisar las siguientes lecciones (capítulo -> lección)- Distancia entre vectores -> Distancia euclidiana\n",
    "- Distancia entre vectores -> Distancia Manhattan\n",
    "\n",
    "Para resolver la tarea, podemos probar diferentes métricas de distancia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe una función que devuelva los k vecinos más cercanos para un $n^{th}$ objeto basándose en una métrica de distancia especificada. A la hora de realizar esta tarea no debe tenerse en cuenta el número de prestaciones de seguro recibidas.\n",
    "Puedes utilizar una implementación ya existente del algoritmo kNN de scikit-learn (consulta [el enlace](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)) o tu propia implementación.\n",
    "Pruébalo para cuatro combinaciones de dos casos- Escalado\n",
    "  - los datos no están escalados\n",
    "  - los datos se escalan con el escalador [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html)\n",
    "- Métricas de distancia\n",
    "  - Euclidiana\n",
    "  - Manhattan\n",
    "\n",
    "Responde a estas preguntas:- ¿El hecho de que los datos no estén escalados afecta al algoritmo kNN? Si es así, ¿cómo se manifiesta?- ¿Qué tan similares son los resultados al utilizar la métrica de distancia Manhattan (independientemente del escalado)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(df, n, k, metric):\n",
    "    nbrs = NearestNeighbors(n_neighbors=n, radius=k, metric=metric).fit(df.loc[:,feature_names], df.loc[:,'insurance_benefits']) # <tu código aquí> \n",
    "    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)\n",
    "    \n",
    "    df_res = pd.concat([\n",
    "        df.iloc[nbrs_indices[0]], \n",
    "        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])\n",
    "        ], axis=1)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se escalan los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_names = ['gender', 'age', 'income', 'family_members']\n",
    "\n",
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.516456</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.244304</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.415190</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.608861</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.787342</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.259494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.646835</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.460759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits\n",
       "3944     0.0  0.307692  0.516456        0.333333                   0\n",
       "1034     0.0  0.384615  0.244304        0.500000                   0\n",
       "3030     0.0  0.323077  0.493671        0.833333                   0\n",
       "1988     1.0  0.630769  0.491139        0.166667                   0\n",
       "2214     0.0  0.692308  0.415190        0.500000                   1\n",
       "434      1.0  0.492308  0.608861        0.333333                   0\n",
       "3190     1.0  0.384615  0.787342        0.333333                   0\n",
       "2157     0.0  0.369231  0.259494        0.000000                   0\n",
       "2402     1.0  0.446154  0.646835        0.166667                   0\n",
       "1591     0.0  0.323077  0.460759        0.000000                   0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a obtener registros similares para uno determinado, para cada combinación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>37300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>37300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>37300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>37300</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.605551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.164414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.124038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.124038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.045361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  income  family_members  insurance_benefits   distance\n",
       "100        0   19   37300               1                   0   0.000000\n",
       "4278       1   19   37300               2                   0   1.414214\n",
       "1831       0   20   37300               2                   0   1.414214\n",
       "2624       1   19   37300               0                   0   1.414214\n",
       "1086       0   22   37300               3                   0   3.605551\n",
       "1806       1   23   37300               0                   0   4.242641\n",
       "3447       1   25   37300               0                   0   6.164414\n",
       "568        1   27   37300               0                   0   8.124038\n",
       "4580       1   27   37300               0                   0   8.124038\n",
       "168        0   30   37300               0                   0  11.045361"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(df, 100, 10, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.472152</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.477215</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.467089</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.456962</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.470886</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.469620</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.467089</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.465823</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.463291</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.482278</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits  distance\n",
       "100      0.0  0.292308  0.472152        0.166667                   0  0.000000\n",
       "4915     0.0  0.292308  0.477215        0.166667                   0  0.005063\n",
       "243      0.0  0.292308  0.467089        0.166667                   0  0.005063\n",
       "1323     0.0  0.292308  0.456962        0.166667                   0  0.015190\n",
       "811      0.0  0.307692  0.470886        0.166667                   0  0.015437\n",
       "4843     0.0  0.307692  0.469620        0.166667                   0  0.015592\n",
       "4524     0.0  0.276923  0.467089        0.166667                   0  0.016196\n",
       "1648     0.0  0.276923  0.465823        0.166667                   0  0.016636\n",
       "3060     0.0  0.307692  0.463291        0.166667                   0  0.017754\n",
       "2795     0.0  0.276923  0.482278        0.166667                   0  0.018418"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(df_scaled, 100, 10, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>37300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>37300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>37300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>37300</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>37300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  income  family_members  insurance_benefits  distance\n",
       "100        0   19   37300               1                   0       0.0\n",
       "2624       1   19   37300               0                   0       2.0\n",
       "1831       0   20   37300               2                   0       2.0\n",
       "4278       1   19   37300               2                   0       2.0\n",
       "1086       0   22   37300               3                   0       5.0\n",
       "1806       1   23   37300               0                   0       6.0\n",
       "3447       1   25   37300               0                   0       8.0\n",
       "4580       1   27   37300               0                   0      10.0\n",
       "568        1   27   37300               0                   0      10.0\n",
       "168        0   30   37300               0                   0      12.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(df, 100, 10, 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.472152</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.477215</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.467089</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.456962</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.470886</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.469620</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.467089</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.450633</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.465823</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.463291</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits  distance\n",
       "100      0.0  0.292308  0.472152        0.166667                   0  0.000000\n",
       "4915     0.0  0.292308  0.477215        0.166667                   0  0.005063\n",
       "243      0.0  0.292308  0.467089        0.166667                   0  0.005063\n",
       "1323     0.0  0.292308  0.456962        0.166667                   0  0.015190\n",
       "811      0.0  0.307692  0.470886        0.166667                   0  0.016650\n",
       "4843     0.0  0.307692  0.469620        0.166667                   0  0.017916\n",
       "4524     0.0  0.276923  0.467089        0.166667                   0  0.020448\n",
       "4630     0.0  0.292308  0.450633        0.166667                   0  0.021519\n",
       "1648     0.0  0.276923  0.465823        0.166667                   0  0.021714\n",
       "3060     0.0  0.307692  0.463291        0.166667                   0  0.024245"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn(df_scaled, 100, 10, 'manhattan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuestas a las preguntas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿El hecho de que los datos no estén escalados afecta al algoritmo kNN? Si es así, ¿cómo se manifiesta?** \n",
    "\n",
    "Sí, el hecho de que los datos no estén escalados puede afectar al algoritmo kNN. El algoritmo kNN utiliza la distancia entre los puntos para calcular la similitud entre ellos y, si los datos no están escalados, es posible que las características con valores grandes tengan un efecto dominante en la distancia, lo que puede hacer que las características con valores pequeños tengan un peso menor. Esto puede llevar a resultados inexactos en el modelo.\n",
    "\n",
    "La falta de escalado también puede afectar la interpretación de los resultados. Por ejemplo, si una característica está en una escala diferente a las otras, puede ser difícil comparar su importancia relativa en el modelo.\n",
    "\n",
    "Para solucionar este problema, es recomendable escalar los datos antes de aplicar el algoritmo kNN. Un enfoque común es escalar los datos para que tengan una media de cero y una desviación estándar de uno. De esta forma, todas las características tienen la misma importancia en la distancia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué tan similares son los resultados al utilizar la métrica de distancia Manhattan (independientemente del escalado)?** \n",
    "\n",
    "En cuanto a la métrica de distancia Manhattan, esta no se ve afectada por el escalado de los datos, ya que solo se basa en la distancia entre los puntos en cada dimensión. Por lo tanto, los resultados utilizando la métrica de distancia Manhattan serán similares independientemente del escalado de los datos. Sin embargo, es importante recordar que la métrica de distancia Manhattan puede ser menos efectiva que la métrica euclidiana en espacios de alta dimensión."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2. ¿Es probable que el cliente reciba una prestación del seguro?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En términos de machine learning podemos considerarlo como una tarea de clasificación binaria."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el valor de `insurance_benefits` superior a cero como objetivo, evalúa si el enfoque de clasificación kNN puede funcionar mejor que el modelo dummy.\n",
    "Instrucciones:\n",
    "- Construye un clasificador basado en KNN y mide su calidad con la métrica F1 para k=1...10 tanto para los datos originales como para los escalados. Sería interesante observar cómo k puede influir en la métrica de evaluación y si el escalado de los datos provoca alguna diferencia. Puedes utilizar una implementación ya existente del algoritmo de clasificación kNN de scikit-learn (consulta [el enlace](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) o tu propia implementación.- Construye un modelo dummy que, en este caso, es simplemente un modelo aleatorio. Debería devolver \"1\" con cierta probabilidad. Probemos el modelo con cuatro valores de probabilidad: 0, la probabilidad de pagar cualquier prestación del seguro, 0.5, 1.\n",
    "La probabilidad de pagar cualquier prestación del seguro puede definirse como\n",
    "$$\n",
    "P\\{\\text{prestación de seguro recibida}\\}=\\frac{\\text{número de clientes que han recibido alguna prestación de seguro}}{\\text{número total de clientes}}.\n",
    "$$\n",
    "\n",
    "Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporción 70:30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сalcula el objetivo\n",
    "df['insurance_benefits_received'] = np.where(df['insurance_benefits'] == 0, 0, 1)\n",
    "df_scaled['insurance_benefits_received'] = np.where(df_scaled['insurance_benefits'] == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4436\n",
       "1     564\n",
       "Name: insurance_benefits_received, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comprueba el desequilibrio de clases con value_counts()\n",
    "df['insurance_benefits_received'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño conjunto entrenamiento: (3500, 4) (3500,)\n",
      "Tamaño conjunto prueba: (1500, 4) (1500,)\n"
     ]
    }
   ],
   "source": [
    "# Establecemos las características y objetivos para el dataset no escalado\n",
    "features = df.drop(['insurance_benefits_received', 'insurance_benefits'], axis=1)\n",
    "target = df['insurance_benefits_received']\n",
    "\n",
    "# Dividimos los datos en un dataset de entrenamiento y prueba (proporción 70:30)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,\n",
    "                                                                             target, \n",
    "                                                                             test_size=0.30,\n",
    "                                                                             random_state=12345)\n",
    "\n",
    "# Comprobamos que la división se realizó correctamente, llamando a shape\n",
    "print('Tamaño conjunto entrenamiento:', features_train.shape, target_train.shape)\n",
    "print('Tamaño conjunto prueba:', features_test.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño conjunto entrenamiento escalado: (3500, 4) (3500,)\n",
      "Tamaño conjunto prueba escalado: (1500, 4) (1500,)\n"
     ]
    }
   ],
   "source": [
    "# Establecemos las características y objetivos para el dataset escalado 'df_scaled'\n",
    "features_scaled = df_scaled.drop(['insurance_benefits_received', 'insurance_benefits'], axis=1)\n",
    "target_scaled = df_scaled['insurance_benefits_received']\n",
    "\n",
    "# Dividimos los datos en un dataset de entrenamiento y prueba (propoción 70:30)\n",
    "features_train_sc, features_test_sc, target_train_sc, target_test_sc = train_test_split(features_scaled,\n",
    "                                                                             target_scaled, \n",
    "                                                                             test_size=0.30,\n",
    "                                                                             random_state=12345)\n",
    "\n",
    "# Comprobamos que la división se realizó correctamente, llamando a shape\n",
    "print('Tamaño conjunto entrenamiento escalado:', features_train_sc.shape, target_train_sc.shape)\n",
    "print('Tamaño conjunto prueba escalado:', features_test_sc.shape, target_test_sc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "# si tienes algún problema con la siguiente línea, reinicia el kernel y ejecuta el cuaderno de nuevo    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print('Matriz de confusión')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar la salida de un modelo aleatorio\n",
    "\n",
    "def rnd_model_predict(P, size, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    return rng.binomial(n=1, p=P, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilidad: 0.00\n",
      "F1: 0.00\n",
      "Matriz de confusión\n",
      "[[0.8872 0.    ]\n",
      " [0.1128 0.    ]]\n",
      "\n",
      "La probabilidad: 0.11\n",
      "F1: 0.12\n",
      "Matriz de confusión\n",
      "[[0.7914 0.0958]\n",
      " [0.0994 0.0134]]\n",
      "\n",
      "La probabilidad: 0.50\n",
      "F1: 0.20\n",
      "Matriz de confusión\n",
      "[[0.456  0.4312]\n",
      " [0.053  0.0598]]\n",
      "\n",
      "La probabilidad: 1.00\n",
      "F1: 0.20\n",
      "Matriz de confusión\n",
      "[[0.     0.8872]\n",
      " [0.     0.1128]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for P in [0, df['insurance_benefits_received'].sum() / len(df), 0.5, 1]:\n",
    "\n",
    "    print(f'La probabilidad: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P, df.shape[0])\n",
    "        \n",
    "    eval_classifier(df['insurance_benefits_received'], y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_neighbors:1\n",
      "F1: 0.61\n",
      "Matriz de confusión\n",
      "[[0.87       0.02133333]\n",
      " [0.052      0.05666667]]\n",
      "\n",
      "K_neighbors:2\n",
      "F1: 0.41\n",
      "Matriz de confusión\n",
      "[[0.88733333 0.004     ]\n",
      " [0.08       0.02866667]]\n",
      "\n",
      "K_neighbors:3\n",
      "F1: 0.41\n",
      "Matriz de confusión\n",
      "[[0.88       0.01133333]\n",
      " [0.078      0.03066667]]\n",
      "\n",
      "K_neighbors:4\n",
      "F1: 0.28\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.09066667 0.018     ]]\n",
      "\n",
      "K_neighbors:5\n",
      "F1: 0.27\n",
      "Matriz de confusión\n",
      "[[0.88533333 0.006     ]\n",
      " [0.09066667 0.018     ]]\n",
      "\n",
      "K_neighbors:6\n",
      "F1: 0.11\n",
      "Matriz de confusión\n",
      "[[0.89       0.00133333]\n",
      " [0.102      0.00666667]]\n",
      "\n",
      "K_neighbors:7\n",
      "F1: 0.11\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.102      0.00666667]]\n",
      "\n",
      "K_neighbors:8\n",
      "F1: 0.07\n",
      "Matriz de confusión\n",
      "[[0.89133333 0.        ]\n",
      " [0.10466667 0.004     ]]\n",
      "\n",
      "K_neighbors:9\n",
      "F1: 0.08\n",
      "Matriz de confusión\n",
      "[[0.89133333 0.        ]\n",
      " [0.104      0.00466667]]\n",
      "\n",
      "K_neighbors:10\n",
      "F1: 0.00\n",
      "Matriz de confusión\n",
      "[[0.89133333 0.        ]\n",
      " [0.10866667 0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se construye un bucle for para obtener el puntaje F1 para el dataset sin escalar\n",
    "for k in range(1, 11):\n",
    "    \n",
    "    neigh = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(features_train, target_train)\n",
    "    predictions = neigh.predict(features_test)\n",
    "    \n",
    "    print(f'K_neighbors:{k}')\n",
    "    eval_classifier(target_test, predictions)\n",
    "    \n",
    "    print()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_neighbors:1\n",
      "F1: 0.97\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.00466667 0.104     ]]\n",
      "\n",
      "K_neighbors:2\n",
      "F1: 0.93\n",
      "Matriz de confusión\n",
      "[[8.90666667e-01 6.66666667e-04]\n",
      " [1.40000000e-02 9.46666667e-02]]\n",
      "\n",
      "K_neighbors:3\n",
      "F1: 0.95\n",
      "Matriz de confusión\n",
      "[[0.88933333 0.002     ]\n",
      " [0.00866667 0.1       ]]\n",
      "\n",
      "K_neighbors:4\n",
      "F1: 0.91\n",
      "Matriz de confusión\n",
      "[[0.88933333 0.002     ]\n",
      " [0.01666667 0.092     ]]\n",
      "\n",
      "K_neighbors:5\n",
      "F1: 0.92\n",
      "Matriz de confusión\n",
      "[[0.88666667 0.00466667]\n",
      " [0.01133333 0.09733333]]\n",
      "\n",
      "K_neighbors:6\n",
      "F1: 0.90\n",
      "Matriz de confusión\n",
      "[[0.89       0.00133333]\n",
      " [0.018      0.09066667]]\n",
      "\n",
      "K_neighbors:7\n",
      "F1: 0.92\n",
      "Matriz de confusión\n",
      "[[0.88733333 0.004     ]\n",
      " [0.01266667 0.096     ]]\n",
      "\n",
      "K_neighbors:8\n",
      "F1: 0.90\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.01733333 0.09133333]]\n",
      "\n",
      "K_neighbors:9\n",
      "F1: 0.92\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.01466667 0.094     ]]\n",
      "\n",
      "K_neighbors:10\n",
      "F1: 0.88\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.02133333 0.08733333]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se construye un bucle for para obtener el puntaje F1 para el dataset escalado\n",
    "for k in range(1, 11):\n",
    "    \n",
    "    neigh = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(features_train_sc, target_train)\n",
    "    predictions = neigh.predict(features_test_sc)\n",
    "    \n",
    "    print(f'K_neighbors:{k}')\n",
    "    eval_classifier(target_test, predictions)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el primer modelo que usa un modelo aleatorio, se puede observar que a medida que aumenta la probabilidad de predecir que un cliente recibirá beneficios de seguro (de 0 a 1), la puntuación F1 del modelo también aumenta. Sin embargo, las puntuaciones son bajas (0.12 y 0.20), lo que indica que el rendimiento del modelo no es muy bueno. La matriz de confusión también indica que hay una gran cantidad de falsos negativos y falsos positivos, lo que demuestra la falta de precisión y sensibilidad del modelo.\n",
    "\n",
    "Para el modelo KNN con los datos sin escalar, la puntuación F1 es máxima (0.60) cuando se usa solo 1 vecino más cercano. A medida que aumenta el número de vecinos, la puntuación F1 disminuye, lo que indica que el rendimiento del modelo empeora. Esto podría deberse a que a medida que aumenta el número de vecinos, el modelo se vuelve más sesgado y menos capaz de captar las sutilezas en los datos.\n",
    "\n",
    "Para el modelo KNN con los datos escalados, la puntuación F1 es significativamente mejor en comparación con los datos sin escalar. Las puntuaciones F1 son consistentemente altas, alcanzando un máximo de 0.97 con 1 vecino más cercano y todavía manteniendo una puntuación alta de 0.91 con 10 vecinos. Esto indica que escalar los datos ha mejorado significativamente el rendimiento del modelo KNN. Las matrices de confusión también muestran que hay menos falsos negativos y falsos positivos en comparación con los datos sin escalar.\n",
    "\n",
    "En conclusión, el modelo KNN con datos escalados proporciona el mejor rendimiento en términos de la puntuación F1. Es importante destacar que el escalado de los datos tuvo un impacto positivo significativo en el rendimiento del modelo. Para futuros trabajos, se podría investigar por qué el escalado tuvo tal impacto y si hay otras técnicas de preprocesamiento que podrían mejorar aún más el rendimiento del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3. Regresión (con regresión lineal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `insurance_benefits` como objetivo, evalúa cuál sería la RECM de un modelo de regresión lineal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye tu propia implementación de regresión lineal. Para ello, recuerda cómo está formulada la solución de la tarea de regresión lineal en términos de LA. Comprueba la RECM tanto para los datos originales como para los escalados. ¿Puedes ver alguna diferencia en la RECM con respecto a estos dos casos?\n",
    "\n",
    "Denotemos- $X$: matriz de características; cada fila es un caso, cada columna es una característica, la primera columna está formada por unidades- $y$ — objetivo (un vector)- $\\hat{y}$ — objetivo estimado (un vector)- $w$ — vector de pesos\n",
    "La tarea de regresión lineal en el lenguaje de las matrices puede formularse así:\n",
    "$$\n",
    "y = Xw\n",
    "$$\n",
    "\n",
    "El objetivo de entrenamiento es entonces encontrar esa $w$ w que minimice la distancia L2 (ECM) entre $Xw$ y $y$:\n",
    "\n",
    "$$\n",
    "\\min_w d_2(Xw, y) \\quad \\text{or} \\quad \\min_w \\text{MSE}(Xw, y)\n",
    "$$\n",
    "\n",
    "Parece que hay una solución analítica para lo anteriormente expuesto:\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "La fórmula anterior puede servir para encontrar los pesos $w$ y estos últimos pueden utilizarse para calcular los valores predichos\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporción 70:30. Utiliza la métrica RECM para evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        self.weights = (np.linalg.inv(X.T.dot(X)).dot(X.T)).dot(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        y_pred = X.dot(self.weights)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'RMSE: {rmse:.2f}')\n",
    "    \n",
    "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "    print(f'R2: {r2_score:.2f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.34323855e-02 -4.11580861e-02 -1.19007214e-05 -4.53191845e-02]\n",
      "RMSE: 0.38\n",
      "R2: 0.56\n"
     ]
    }
   ],
   "source": [
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 4. Ofuscar datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mejor es ofuscar los datos multiplicando las características numéricas (recuerda que se pueden ver como la matriz $X$) por una matriz invertible $P$. \n",
    "\n",
    "$$\n",
    "X' = X \\times P\n",
    "$$\n",
    "\n",
    "Trata de hacerlo y comprueba cómo quedarán los valores de las características después de la transformación. Por cierto, la propiedad de invertibilidad es importante aquí, así que asegúrate de que $P$ sea realmente invertible.\n",
    "\n",
    "Puedes revisar la lección 'Matrices y operaciones matriciales -> Multiplicación de matrices' para recordar la regla de multiplicación de matrices y su implementación con NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pn.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar una matriz aleatoria $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar que la matriz P sea invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41467992, -1.43783972,  0.62798546,  1.14001268],\n",
       "       [-1.06101789,  0.44219337,  0.1329549 ,  1.18425933],\n",
       "       [ 1.42362442,  1.60461607, -2.0553823 , -1.53699695],\n",
       "       [-0.11128575, -0.65813802,  1.74995517, -0.11816316]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(P)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Puedes adivinar la edad o los ingresos de los clientes después de la transformación?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, después de la transformación (ofuscación de los datos) es muy difícil, si no imposible, adivinar la edad o los ingresos de los clientes. Al multiplicar la matriz de características numéricas por una matriz invertible aleatoria $P$, hemos cambiado la estructura y las relaciones entre las variables, lo que dificulta la interpretación de los datos originales. Es importante destacar que la ofuscación de los datos es un proceso destinado a proteger la privacidad de los datos, pero puede tener un efecto negativo en la capacidad de hacer análisis detallados y precisos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Puedes recuperar los datos originales de $X'$ si conoces $P$? Intenta comprobarlo a través de los cálculos moviendo $P$ del lado derecho de la fórmula anterior al izquierdo. En este caso las reglas de la multiplicación matricial son realmente útiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.10000000e+01,  4.96000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-4.47363596e-12,  4.60000000e+01,  3.80000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-2.51586878e-12,  2.90000000e+01,  2.10000000e+04,\n",
       "         9.52452315e-13],\n",
       "       ...,\n",
       "       [-1.92837871e-12,  2.00000000e+01,  3.39000000e+04,\n",
       "         2.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.20000000e+01,  3.27000000e+04,\n",
       "         3.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.80000000e+01,  4.06000000e+04,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dot(P).dot(np.linalg.inv(P))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra los tres casos para algunos clientes- Datos originales\n",
    "- El que está transformado- El que está invertido (recuperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0    21 41700     2]\n",
      "\n",
      "[ 5345.60393712 18803.22720286 15479.14837264 38663.06186284]\n",
      "\n",
      "[-4.84498208e-12  2.10000000e+01  4.17000000e+04  2.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(X[3])\n",
    "print()\n",
    "print(X.dot(P)[3])\n",
    "print()\n",
    "print(X.dot(P).dot(np.linalg.inv(P))[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguramente puedes ver que algunos valores no son exactamente iguales a los de los datos originales. ¿Cuál podría ser la razón de ello?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La razón por la cual algunos valores no son exactamente iguales a los de los datos originales se debe a errores de redondeo y precisión numérica durante los cálculos de la ofuscación y la recuperación de datos. Estos errores son inherentes al uso de números de punto flotante en las computadoras, ya que algunos números decimales no se pueden representar con precisión finita en el sistema de punto flotante. Por lo tanto, incluso si la matriz $P$ es invertible, la recuperación exacta de los datos originales puede no ser posible debido a estos errores de redondeo y precisión numérica."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de que la ofuscación de datos puede funcionar con regresión lineal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto la tarea de regresión se ha resuelto con la regresión lineal. Tu siguiente tarea es demostrar _analytically_ que el método de ofuscación no afectará a la regresión lineal en términos de valores predichos, es decir, que sus valores seguirán siendo los mismos. ¿Lo puedes creer? Pues no hace falta que lo creas, ¡tienes que que demostrarlo!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, los datos están ofuscados y ahora tenemos $X \\times P$ en lugar de tener solo $X$. En consecuencia, hay otros pesos $w_P$ como\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y \\quad \\Rightarrow \\quad w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$\n",
    "\n",
    "¿Cómo se relacionarían $w$ y $w_P$ si simplificáramos la fórmula de $w_P$ anterior? \n",
    "\n",
    "¿Cuáles serían los valores predichos con $w_P$? \n",
    "\n",
    "¿Qué significa esto para la calidad de la regresión lineal si esta se mide mediante la RECM?\n",
    "Revisa el Apéndice B Propiedades de las matrices al final del cuaderno. ¡Allí encontrarás fórmulas muy útiles!\n",
    "\n",
    "No es necesario escribir código en esta sección, basta con una explicación analítica."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Las respuestas a las tres preguntas anteriores son las siguientes:\n",
    "\n",
    "* La relación entre $w$ y $w_P$ al simplificar la fórmula de $w_P$ es la siguiente:\n",
    "$$\n",
    "w = X^{-1} y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = P^{-1}X^{-1}y\n",
    "$$\n",
    "\n",
    "Esto muestra que ambos pesos están relacionados con la inversa de la matriz $(XP)^T XP$, lo que destaca la importancia de utilizar una matriz que tenga una inversa.\n",
    "\n",
    "* Los valores predichos con $w_P$ serán iguales a los valores predichos con $w$, ya que la única diferencia entre las dos fórmulas es el uso de la matriz $XP$ en lugar de la matriz $X$. Como ambos pesos se utilizan para ajustar la regresión lineal a los datos de entrenamiento, la calidad de la regresión se mantiene constante.\n",
    "\n",
    "* En resumen, la calidad de la regresión lineal se mide comúnmente mediante la RECM, que es la raíz cuadrada del error cuadrático medio entre los valores observados y los valores predichos por el modelo de regresión. La relación entre $w$ y $w_P$, y los valores predichos por ambas fórmulas, tienen un impacto en la calidad de la regresión medida por la RECM, ya que depende de la precisión de los datos de entrada y de cómo se ajusten al modelo de regresión. Por lo tanto, es importante tener en cuenta la interpretación de los coeficientes de regresión, la capacidad del modelo para generalizar a nuevos datos, y la validez de las suposiciones subyacentes de la regresión lineal al evaluar la calidad de un modelo de regresión."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prueba analítica**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente es con el peso original:\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w = X^{-1} X^{-T} X^T y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w = X^{-1} (X^{-T} X^T) y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w = X^{-1} I y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w = X^{-1} y\n",
    "$$\n",
    "\n",
    "Y esto con el peso ofuscado:\n",
    "$$\n",
    "w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = [(XP)^T (XP)]^{-1} (XP)^T y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = (XP)^{-1} (XP)^{-T} (XP)^T Y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} X^{-T} P^{-T} P^T X^T y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} X^{-T} (P^{-T} P^T) X^T y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} X^{-T} I X^T y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} (X^{-T} X^T) y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} I y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} y\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de regresión lineal con ofuscación de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, probemos que la regresión lineal pueda funcionar, en términos computacionales, con la transformación de ofuscación elegida.\n",
    "Construye un procedimiento o una clase que ejecute la regresión lineal opcionalmente con la ofuscación. Puedes usar una implementación de regresión lineal de scikit-learn o tu propia implementación.\n",
    "Ejecuta la regresión lineal para los datos originales y los ofuscados, compara los valores predichos y los valores de las métricas RMSE y $R^2$. ¿Hay alguna diferencia?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedimiento**\n",
    "\n",
    "- Crea una matriz cuadrada $P$ de números aleatorios.- Comprueba que sea invertible. Si no lo es, repite el primer paso hasta obtener una matriz invertible.- <Se utilizará la matriz P construida en la tarea 3>\n",
    "- Utiliza $XP$ como la nueva matriz de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.24612725e-02 -5.30283402e-02 -1.11128361e-05 -4.35917698e-02]\n",
      "RMSE: 0.40\n",
      "R2: 0.57\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Datos con la versión original X\n",
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1984)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03585834 -0.09890605  0.01390955  0.03753185]\n",
      "RMSE: 0.40\n",
      "R2: 0.57\n"
     ]
    }
   ],
   "source": [
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "XP = X.dot(P)\n",
    "\n",
    "X_trainP, X_testP, y_trainP, y_testP = train_test_split(XP, y, test_size=0.3, random_state=1984)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_trainP, y_trainP)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_testP)\n",
    "eval_regressor(y_testP, y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras analizar los códigos previamente mostrados, se puede observar que las métricas obtenidas son muy similares en ambos casos, lo que indica que la ofuscación de los datos no tiene un impacto significativo en el análisis y predicción de los mismos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de resultados: Impacto de la ofuscación de datos en el análisis\n",
    "\n",
    "Después de realizar un análisis exploratorio de datos (EDA) y abordar cada tarea del proyecto, se ha evaluado el impacto de la ofuscación de datos en los resultados y conclusiones obtenidos. A continuación se presentan los hallazgos principales:\n",
    "\n",
    "### Tarea 1: Búsqueda de clientes similares\n",
    "Se aplicaron métodos de medición de distancia (euclidiana y Manhattan) en datos escalados y no escalados para encontrar los k vecinos más similares a un cliente seleccionado. Se determinó que el escalado puede ser beneficioso en ciertos casos para mejorar los resultados de la búsqueda de vecinos cercanos. Sin embargo, la ofuscación de datos no tuvo un impacto significativo en los resultados obtenidos.\n",
    "\n",
    "### Tareas 3 y 4: Modelo de regresión lineal y ofuscación de datos\n",
    "Se construyó un modelo de regresión lineal utilizando la métrica F1 como evaluación. Para garantizar la seguridad de los datos de los usuarios, se implementó una matriz de ofuscación P que codifica los datos. Se observó que la matriz de ofuscación P no tuvo un impacto significativo en los resultados del modelo de regresión lineal basado en la métrica F1.\n",
    "\n",
    "En resumen, se encontró que la ofuscación de datos no afecta de manera significativa los resultados y conclusiones obtenidos en el análisis. Tanto en la tarea de búsqueda de clientes similares como en el modelo de regresión lineal, se verificó que la ofuscación de datos no altera de manera significativa los resultados en comparación con los datos no ofuscados. Además, se determinó que el escalado puede ser útil en ciertos casos para mejorar la búsqueda de vecinos cercanos.\n",
    "\n",
    "Estos hallazgos demuestran que es posible proteger los datos personales mediante la ofuscación sin comprometer la calidad y los resultados de los modelos de Machine Learning. La ofuscación de datos es una estrategia efectiva para preservar la privacidad de los datos mientras se mantienen conclusiones sólidas y se obtienen resultados confiables en el análisis de datos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
